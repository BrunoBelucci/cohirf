{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae9ab206",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67705973",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cohirf.experiment.open_ml_clustering_experiment import OpenmlClusteringExperiment\n",
    "from cohirf.experiment.hpo_open_ml_clustering_experiment import HPOOpenmlClusteringExperiment\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from IPython.display import clear_output\n",
    "import optuna\n",
    "from cohirf.models.batch_cohirf import BatchCoHiRF\n",
    "from cohirf.models.cohirf import BaseCoHiRF\n",
    "from sklearn.cluster import DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a5a971e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_dir = Path('/home/belucci/code/cohirf/results') / 'real'\n",
    "results_dir = Path(\"/home/users/belucci/cohirf/results\") / \"real\"\n",
    "results_dir.mkdir(parents=True, exist_ok=True)\n",
    "mlflow_tracking_uri = f\"sqlite:///{results_dir}/mlflow.db\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9217b561",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_params = dict(\n",
    "    profile_memory=False,\n",
    "    mlflow_tracking_uri=mlflow_tracking_uri,\n",
    "\tcheck_if_exists=False,\n",
    "\tverbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07318299",
   "metadata": {},
   "source": [
    "# KDD 99"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5c1a27",
   "metadata": {},
   "source": [
    "## KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01111a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            ARI      Time   Memory\n",
      "count  1.000000  1.000000     1.00\n",
      "mean   0.359913  2.222778  4797.82\n",
      "std         NaN       NaN      NaN\n",
      "min    0.359913  2.222778  4797.82\n",
      "25%    0.359913  2.222778  4797.82\n",
      "50%    0.359913  2.222778  4797.82\n",
      "75%    0.359913  2.222778  4797.82\n",
      "max    0.359913  2.222778  4797.82\n"
     ]
    }
   ],
   "source": [
    "seeds = [i for i in range(1)]\n",
    "aris = []\n",
    "times = []\n",
    "memories = []\n",
    "for seed in seeds:\n",
    "    experiment = OpenmlClusteringExperiment(\n",
    "        # model\n",
    "        experiment_name=\"test\",\n",
    "        model=\"KMeans\",\n",
    "        seed_model=0,\n",
    "        # dataset\n",
    "        dataset_id=1110,\n",
    "        standardize=True,\n",
    "        raise_on_error=True,\n",
    "        **experiment_params,\n",
    "    )\n",
    "    result = experiment.run(return_results=True)[0]\n",
    "    ari = result[\"evaluate_model_return\"][\"adjusted_rand\"]\n",
    "    time = result[\"fit_model_return\"][\"elapsed_time\"]\n",
    "    max_memory = result[\"max_memory_used_after_fit\"]\n",
    "    aris.append(ari)\n",
    "    times.append(time)\n",
    "    memories.append(max_memory)\n",
    "clear_output(wait=True)\n",
    "df = pd.DataFrame({\"ARI\": aris, \"Time\": times, \"Memory\": memories})\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4960a155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            ARI       Time   Memory\n",
      "count  1.000000   1.000000     1.00\n",
      "mean  -0.003163  25.386191  4274.88\n",
      "std         NaN        NaN      NaN\n",
      "min   -0.003163  25.386191  4274.88\n",
      "25%   -0.003163  25.386191  4274.88\n",
      "50%   -0.003163  25.386191  4274.88\n",
      "75%   -0.003163  25.386191  4274.88\n",
      "max   -0.003163  25.386191  4274.88\n"
     ]
    }
   ],
   "source": [
    "seeds = [i for i in range(1)]\n",
    "aris = []\n",
    "times = []\n",
    "memories = []\n",
    "for seed in seeds:\n",
    "    experiment = OpenmlClusteringExperiment(\n",
    "        # model\n",
    "        experiment_name=\"test\",\n",
    "        model=\"CoHiRF\",\n",
    "        model_params=dict(n_samples_representative=10000),\n",
    "        seed_model=0,\n",
    "        # dataset\n",
    "        dataset_id=1110,\n",
    "        standardize=True,\n",
    "        raise_on_error=True,\n",
    "        **experiment_params,\n",
    "    )\n",
    "    result = experiment.run(return_results=True)[0]\n",
    "    ari = result[\"evaluate_model_return\"][\"adjusted_rand\"]\n",
    "    time = result[\"fit_model_return\"][\"elapsed_time\"]\n",
    "    max_memory = result[\"max_memory_used_after_fit\"]\n",
    "    aris.append(ari)\n",
    "    times.append(time)\n",
    "    memories.append(max_memory)\n",
    "clear_output(wait=True)\n",
    "df = pd.DataFrame({\"ARI\": aris, \"Time\": times, \"Memory\": memories})\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cd8325d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory required: 0.75 GB\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "shape = (10000, 10000)\n",
    "itemsize = np.dtype(np.float64).itemsize  # 8 bytes for float64\n",
    "total_bytes = shape[0] * shape[1] * itemsize\n",
    "total_gb = total_bytes / (1024 ** 3)\n",
    "print(f\"Memory required: {total_gb:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fa24267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            ARI       Time  Memory\n",
      "count  1.000000   1.000000     1.0\n",
      "mean   0.164858  69.262438  4101.2\n",
      "std         NaN        NaN     NaN\n",
      "min    0.164858  69.262438  4101.2\n",
      "25%    0.164858  69.262438  4101.2\n",
      "50%    0.164858  69.262438  4101.2\n",
      "75%    0.164858  69.262438  4101.2\n",
      "max    0.164858  69.262438  4101.2\n"
     ]
    }
   ],
   "source": [
    "seeds = [i for i in range(1)]\n",
    "aris = []\n",
    "times = []\n",
    "memories = []\n",
    "for seed in seeds:\n",
    "    experiment = OpenmlClusteringExperiment(\n",
    "        # model\n",
    "        experiment_name=\"test\",\n",
    "        model=\"BatchCoHiRF-1iter\",\n",
    "        model_params=dict(verbose=1),\n",
    "        n_jobs=10,\n",
    "        # model_params=dict(n_samples_representative=10000),\n",
    "        seed_model=0,\n",
    "        # dataset\n",
    "        dataset_id=1110,\n",
    "        standardize=True,\n",
    "        # raise_on_error=True,\n",
    "        **experiment_params,\n",
    "    )\n",
    "    result = experiment.run(return_results=True)[0]\n",
    "    ari = result[\"evaluate_model_return\"][\"adjusted_rand\"]\n",
    "    time = result[\"fit_model_return\"][\"elapsed_time\"]\n",
    "    max_memory = result[\"max_memory_used_after_fit\"]\n",
    "    aris.append(ari)\n",
    "    times.append(time)\n",
    "    memories.append(max_memory)\n",
    "clear_output(wait=True)\n",
    "df = pd.DataFrame({\"ARI\": aris, \"Time\": times, \"Memory\": memories})\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a67e0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cls = BatchCoHiRF\n",
    "model_params = dict(\n",
    "    cohirf_model=BaseCoHiRF,\n",
    "    cohirf_kwargs=dict(base_model=DBSCAN, max_iter=1),\n",
    "    n_batches=1000,\n",
    "\tn_jobs=10,\n",
    "\tverbose=1,\n",
    ")\n",
    "search_space = dict(\n",
    "\tcohirf_kwargs=dict(\n",
    "\t\tn_features=optuna.distributions.FloatDistribution(0.1, 1),\n",
    "\t\trepetitions=optuna.distributions.IntDistribution(1, 10),\n",
    "\t\tbase_model_kwargs=dict(\n",
    "\t\t\teps=optuna.distributions.FloatDistribution(1e-1, 10),\n",
    "\t\t\tmin_samples=optuna.distributions.IntDistribution(2, 50),\n",
    "\t\t),\n",
    "\t)\n",
    ")\n",
    "default_values = [\n",
    "\tdict(\n",
    "\t\tcohirf_kwargs=dict(\n",
    "\t\t\tn_features=0.3,\n",
    "\t\t\trepetitions=5,\n",
    "\t\t\tbase_model_kwargs=dict(\n",
    "\t\t\t\teps=0.5,\n",
    "\t\t\t\tmin_samples=5,\n",
    "\t\t\t),\n",
    "\t\t)\n",
    "\t),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f697ef27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            ARI       Time    Memory\n",
      "count  1.000000   1.000000     1.000\n",
      "mean   0.065867  83.848245  4100.824\n",
      "std         NaN        NaN       NaN\n",
      "min    0.065867  83.848245  4100.824\n",
      "25%    0.065867  83.848245  4100.824\n",
      "50%    0.065867  83.848245  4100.824\n",
      "75%    0.065867  83.848245  4100.824\n",
      "max    0.065867  83.848245  4100.824\n"
     ]
    }
   ],
   "source": [
    "seeds = [i for i in range(1)]\n",
    "aris = []\n",
    "times = []\n",
    "memories = []\n",
    "for seed in seeds:\n",
    "    experiment = OpenmlClusteringExperiment(\n",
    "        # model\n",
    "        experiment_name=\"test\",\n",
    "        # model=\"BatchCoHiRF-DBSCAN-1iter\",\n",
    "        model=model_cls,\n",
    "        model_params=model_params,\n",
    "        n_jobs=10,\n",
    "        # search_space=search_space,\n",
    "        # default_values=default_values,\n",
    "        seed_model=0,\n",
    "        # dataset\n",
    "        dataset_id=1110,\n",
    "        standardize=True,\n",
    "        raise_on_error=True,\n",
    "        **experiment_params,\n",
    "    )\n",
    "    result = experiment.run(return_results=True)[0]\n",
    "    ari = result[\"evaluate_model_return\"][\"adjusted_rand\"]\n",
    "    time = result[\"fit_model_return\"][\"elapsed_time\"]\n",
    "    max_memory = result[\"max_memory_used_after_fit\"]\n",
    "    aris.append(ari)\n",
    "    times.append(time)\n",
    "    memories.append(max_memory)\n",
    "clear_output(wait=True)\n",
    "df = pd.DataFrame({\"ARI\": aris, \"Time\": times, \"Memory\": memories})\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b21e64f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           ARI        Time    Memory\n",
      "count  1.00000    1.000000     1.000\n",
      "mean   0.04139  198.484997  4896.528\n",
      "std        NaN         NaN       NaN\n",
      "min    0.04139  198.484997  4896.528\n",
      "25%    0.04139  198.484997  4896.528\n",
      "50%    0.04139  198.484997  4896.528\n",
      "75%    0.04139  198.484997  4896.528\n",
      "max    0.04139  198.484997  4896.528\n"
     ]
    }
   ],
   "source": [
    "seeds = [i for i in range(1)]\n",
    "aris = []\n",
    "times = []\n",
    "memories = []\n",
    "for seed in seeds:\n",
    "    experiment = OpenmlClusteringExperiment(\n",
    "        # model\n",
    "        experiment_name=\"test\",\n",
    "        model=\"BatchCoHiRF-KernelRBF-1iter\",\n",
    "        n_jobs=10,\n",
    "        # search_space=search_space,\n",
    "        # default_values=default_values,\n",
    "        seed_model=0,\n",
    "        # dataset\n",
    "        dataset_id=1110,\n",
    "        standardize=True,\n",
    "        raise_on_error=True,\n",
    "        **experiment_params,\n",
    "    )\n",
    "    result = experiment.run(return_results=True)[0]\n",
    "    ari = result[\"evaluate_model_return\"][\"adjusted_rand\"]\n",
    "    time = result[\"fit_model_return\"][\"elapsed_time\"]\n",
    "    max_memory = result[\"max_memory_used_after_fit\"]\n",
    "    aris.append(ari)\n",
    "    times.append(time)\n",
    "    memories.append(max_memory)\n",
    "clear_output(wait=True)\n",
    "df = pd.DataFrame({\"ARI\": aris, \"Time\": times, \"Memory\": memories})\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83aa567f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67e36a72bbf84114b13f7373ffa31d04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Combinations completed:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: not a git repository (or any parent up to mount point /mnt/nfs)\n",
      "Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to restart the Kernel. \n",
      "\u001b[1;31mrequest to http://localhost:8888/api/kernels/385e0cf1-e200-4434-ad7c-dc216a9eb721/restart?1752853869758 failed, reason: connect ECONNREFUSED 127.0.0.1:8888. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "seeds = [i for i in range(1)]\n",
    "aris = []\n",
    "times = []\n",
    "memories = []\n",
    "for seed in seeds:\n",
    "    experiment = OpenmlClusteringExperiment(\n",
    "        # model\n",
    "        experiment_name=\"test\",\n",
    "        model=\"BatchCoHiRF-SC-SRGF\",\n",
    "        model_params=dict(n_batches=100, cohirf_kwargs=dict(n_samples_representative=10000)),\n",
    "        n_jobs=1,\n",
    "        # search_space=search_space,\n",
    "        # default_values=default_values,\n",
    "        seed_model=0,\n",
    "        # dataset\n",
    "        dataset_id=1110,\n",
    "        standardize=True,\n",
    "        raise_on_error=True,\n",
    "        **experiment_params,\n",
    "    )\n",
    "    result = experiment.run(return_results=True)[0]\n",
    "    ari = result[\"evaluate_model_return\"][\"adjusted_rand\"]\n",
    "    time = result[\"fit_model_return\"][\"elapsed_time\"]\n",
    "    max_memory = result[\"max_memory_used_after_fit\"]\n",
    "    aris.append(ari)\n",
    "    times.append(time)\n",
    "    memories.append(max_memory)\n",
    "clear_output(wait=True)\n",
    "df = pd.DataFrame({\"ARI\": aris, \"Time\": times, \"Memory\": memories})\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6c9a38",
   "metadata": {},
   "source": [
    "# MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76855797",
   "metadata": {},
   "source": [
    "## KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a7177f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           ARI      Time    Memory\n",
      "count  1.00000  1.000000     1.000\n",
      "mean   0.28394  5.946795  2598.252\n",
      "std        NaN       NaN       NaN\n",
      "min    0.28394  5.946795  2598.252\n",
      "25%    0.28394  5.946795  2598.252\n",
      "50%    0.28394  5.946795  2598.252\n",
      "75%    0.28394  5.946795  2598.252\n",
      "max    0.28394  5.946795  2598.252\n"
     ]
    }
   ],
   "source": [
    "seeds = [i for i in range(1)]\n",
    "aris = []\n",
    "times = []\n",
    "memories = []\n",
    "for seed in seeds:\n",
    "    experiment = OpenmlClusteringExperiment(\n",
    "        # model\n",
    "        experiment_name=\"test\",\n",
    "        model=\"KMeans\",\n",
    "        seed_model=0,\n",
    "        # dataset\n",
    "        dataset_id=554,\n",
    "        standardize=True,\n",
    "        raise_on_error=True,\n",
    "        **experiment_params,\n",
    "    )\n",
    "    result = experiment.run(return_results=True)[0]\n",
    "    ari = result[\"evaluate_model_return\"][\"adjusted_rand\"]\n",
    "    time = result[\"fit_model_return\"][\"elapsed_time\"]\n",
    "    max_memory = result[\"max_memory_used_after_fit\"]\n",
    "    aris.append(ari)\n",
    "    times.append(time)\n",
    "    memories.append(max_memory)\n",
    "clear_output(wait=True)\n",
    "df = pd.DataFrame({\"ARI\": aris, \"Time\": times, \"Memory\": memories})\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d5288e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       ARI       Time    Memory\n",
      "count  1.0   1.000000     1.000\n",
      "mean   0.0  47.488333  2974.928\n",
      "std    NaN        NaN       NaN\n",
      "min    0.0  47.488333  2974.928\n",
      "25%    0.0  47.488333  2974.928\n",
      "50%    0.0  47.488333  2974.928\n",
      "75%    0.0  47.488333  2974.928\n",
      "max    0.0  47.488333  2974.928\n"
     ]
    }
   ],
   "source": [
    "seeds = [i for i in range(1)]\n",
    "aris = []\n",
    "times = []\n",
    "memories = []\n",
    "for seed in seeds:\n",
    "    experiment = OpenmlClusteringExperiment(\n",
    "        # model\n",
    "        experiment_name=\"test\",\n",
    "        model=\"DBSCAN\",\n",
    "        seed_model=0,\n",
    "        # dataset\n",
    "        dataset_id=554,\n",
    "        standardize=True,\n",
    "        raise_on_error=True,\n",
    "        **experiment_params,\n",
    "    )\n",
    "    result = experiment.run(return_results=True)[0]\n",
    "    ari = result[\"evaluate_model_return\"][\"adjusted_rand\"]\n",
    "    time = result[\"fit_model_return\"][\"elapsed_time\"]\n",
    "    max_memory = result[\"max_memory_used_after_fit\"]\n",
    "    aris.append(ari)\n",
    "    times.append(time)\n",
    "    memories.append(max_memory)\n",
    "clear_output(wait=True)\n",
    "df = pd.DataFrame({\"ARI\": aris, \"Time\": times, \"Memory\": memories})\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "79b9166b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9481fe7177246c3b1a5f22fde5c69bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Combinations completed:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 36.5 GiB for an array with shape (70000, 70000) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mMemoryError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m seed \u001b[38;5;129;01min\u001b[39;00m seeds:\n\u001b[32m      6\u001b[39m     experiment = OpenmlClusteringExperiment(\n\u001b[32m      7\u001b[39m         \u001b[38;5;66;03m# model\u001b[39;00m\n\u001b[32m      8\u001b[39m         experiment_name=\u001b[33m\"\u001b[39m\u001b[33mtest\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     15\u001b[39m         **experiment_params,\n\u001b[32m     16\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m     result = \u001b[43mexperiment\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreturn_results\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m[\u001b[32m0\u001b[39m]\n\u001b[32m     18\u001b[39m     ari = result[\u001b[33m\"\u001b[39m\u001b[33mevaluate_model_return\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33madjusted_rand\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     19\u001b[39m     time = result[\u001b[33m\"\u001b[39m\u001b[33mfit_model_return\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33melapsed_time\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/ml_experiments/ml_experiments/base_experiment.py:1571\u001b[39m, in \u001b[36mBaseExperiment.run\u001b[39m\u001b[34m(self, return_results)\u001b[39m\n\u001b[32m   1569\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   1570\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1571\u001b[39m     results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_results\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_results\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1572\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/ml_experiments/ml_experiments/base_experiment.py:1503\u001b[39m, in \u001b[36mBaseExperiment._run_experiment\u001b[39m\u001b[34m(self, client, return_results)\u001b[39m\n\u001b[32m   1501\u001b[39m     combination = \u001b[38;5;28mlist\u001b[39m(combination) + [run_id]\n\u001b[32m   1502\u001b[39m     combination_names.append(\u001b[33m\"\u001b[39m\u001b[33mmlflow_run_id\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1503\u001b[39m result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_combination\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1504\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43mcombination\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1505\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcombination_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcombination_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1506\u001b[39m \u001b[43m    \u001b[49m\u001b[43munique_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43munique_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1507\u001b[39m \u001b[43m    \u001b[49m\u001b[43mextra_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1508\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_results\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_results\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1509\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1510\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_results:\n\u001b[32m   1511\u001b[39m     combination_success = result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/ml_experiments/ml_experiments/base_experiment.py:1300\u001b[39m, in \u001b[36mBaseExperiment._run_combination\u001b[39m\u001b[34m(self, combination_names, unique_params, extra_params, return_results, *combination, **kwargs)\u001b[39m\n\u001b[32m   1298\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m   1299\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1300\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs_fn\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/ml_experiments/ml_experiments/base_experiment.py:1247\u001b[39m, in \u001b[36mBaseExperiment._run_mlflow_and_train_model\u001b[39m\u001b[34m(self, combination, unique_params, extra_params, return_results, mlflow_run_id, **kwargs)\u001b[39m\n\u001b[32m   1237\u001b[39m mlflow_client.update_run(mlflow_run_id, status=\u001b[33m\"\u001b[39m\u001b[33mRUNNING\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1238\u001b[39m \u001b[38;5;28mself\u001b[39m._log_run_start_params(\n\u001b[32m   1239\u001b[39m     combination=combination,\n\u001b[32m   1240\u001b[39m     unique_params=unique_params,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1244\u001b[39m     **kwargs,\n\u001b[32m   1245\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1247\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_train_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1248\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcombination\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcombination\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1249\u001b[39m \u001b[43m    \u001b[49m\u001b[43munique_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43munique_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1250\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_results\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_results\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1251\u001b[39m \u001b[43m    \u001b[49m\u001b[43mextra_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1252\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmlflow_run_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmlflow_run_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1253\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1254\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/ml_experiments/ml_experiments/base_experiment.py:1090\u001b[39m, in \u001b[36mBaseExperiment._train_model\u001b[39m\u001b[34m(self, combination, unique_params, extra_params, return_results, mlflow_run_id, **kwargs)\u001b[39m\n\u001b[32m   1078\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._treat_train_model_exception(\n\u001b[32m   1079\u001b[39m         exception,\n\u001b[32m   1080\u001b[39m         combination=combination,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1087\u001b[39m         **kwargs,\n\u001b[32m   1088\u001b[39m     )\n\u001b[32m   1089\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:\n\u001b[32m-> \u001b[39m\u001b[32m1090\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_treat_train_model_exception\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1091\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexception\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1092\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcombination\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcombination\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1093\u001b[39m \u001b[43m        \u001b[49m\u001b[43munique_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43munique_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1094\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1095\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmlflow_run_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmlflow_run_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1096\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresults\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1097\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstart_time\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstart_time\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1098\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_results\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_results\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1099\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1100\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1101\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1102\u001b[39m     total_elapsed_time = time.perf_counter() - start_time\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/ml_experiments/ml_experiments/base_experiment.py:823\u001b[39m, in \u001b[36mBaseExperiment._treat_train_model_exception\u001b[39m\u001b[34m(self, exception, combination, unique_params, extra_params, results, start_time, return_results, mlflow_run_id, **kwargs)\u001b[39m\n\u001b[32m    813\u001b[39m log_and_print_msg(\n\u001b[32m    814\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mError while running\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    815\u001b[39m     verbose=\u001b[38;5;28mself\u001b[39m.verbose,\n\u001b[32m   (...)\u001b[39m\u001b[32m    820\u001b[39m     **unique_params,\n\u001b[32m    821\u001b[39m )\n\u001b[32m    822\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.raise_on_error:\n\u001b[32m--> \u001b[39m\u001b[32m823\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exception\n\u001b[32m    824\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m return_results:\n\u001b[32m    825\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/ml_experiments/ml_experiments/base_experiment.py:1010\u001b[39m, in \u001b[36mBaseExperiment._train_model\u001b[39m\u001b[34m(self, combination, unique_params, extra_params, return_results, mlflow_run_id, **kwargs)\u001b[39m\n\u001b[32m   1008\u001b[39m         results[\u001b[33m\"\u001b[39m\u001b[33mfit_model_return\u001b[39m\u001b[33m\"\u001b[39m] = ret\n\u001b[32m   1009\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1010\u001b[39m     ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1011\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcombination\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcombination\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1012\u001b[39m \u001b[43m        \u001b[49m\u001b[43munique_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43munique_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1013\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1014\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmlflow_run_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmlflow_run_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1015\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1017\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1018\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ret:\n\u001b[32m   1019\u001b[39m         results[\u001b[33m\"\u001b[39m\u001b[33mfit_model_return\u001b[39m\u001b[33m\"\u001b[39m] = ret\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/ml_experiments/ml_experiments/utils.py:131\u001b[39m, in \u001b[36mprofile_time.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    128\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m func(*args, **kwargs)\n\u001b[32m    130\u001b[39m start_time = perf_counter()\n\u001b[32m--> \u001b[39m\u001b[32m131\u001b[39m result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    132\u001b[39m elapsed_time = perf_counter() - start_time\n\u001b[32m    133\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m return_in_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, \u001b[38;5;28mdict\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/ml_experiments/ml_experiments/utils.py:174\u001b[39m, in \u001b[36mprofile_memory.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs_from_func)\u001b[39m\n\u001b[32m    172\u001b[39m     dynamic_enable = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    173\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m dynamic_enable:\n\u001b[32m--> \u001b[39m\u001b[32m174\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs_from_func\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m retval:\n\u001b[32m    177\u001b[39m     mem_usage, result = memory_usage((func, args, kwargs_from_func), max_usage=max_usage, retval=retval, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/cohirf/cohirf/experiment/clustering_experiment.py:190\u001b[39m, in \u001b[36mClusteringExperiment._fit_model\u001b[39m\u001b[34m(self, combination, unique_params, extra_params, mlflow_run_id, **kwargs)\u001b[39m\n\u001b[32m    188\u001b[39m model = kwargs[\u001b[33m'\u001b[39m\u001b[33mload_model_return\u001b[39m\u001b[33m'\u001b[39m][\u001b[33m'\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m    189\u001b[39m X = kwargs[\u001b[33m'\u001b[39m\u001b[33mload_data_return\u001b[39m\u001b[33m'\u001b[39m][\u001b[33m'\u001b[39m\u001b[33mX\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m190\u001b[39m y_pred = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    191\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[33m'\u001b[39m\u001b[33my_pred\u001b[39m\u001b[33m'\u001b[39m: y_pred}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/cohirf/cohirf/models/scsrgf.py:138\u001b[39m, in \u001b[36mSpectralSubspaceRandomization.fit_predict\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    137\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfit_predict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y=\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m138\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m.labels_\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/cohirf/cohirf/models/scsrgf.py:119\u001b[39m, in \u001b[36mSpectralSubspaceRandomization.fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    117\u001b[39m     n_features = \u001b[38;5;28mmax\u001b[39m(n_features, \u001b[32m1\u001b[39m)  \u001b[38;5;66;03m# Ensure at least one feature is selected\u001b[39;00m\n\u001b[32m    118\u001b[39m     X_i = X[:, seq[:n_features]]\n\u001b[32m--> \u001b[39m\u001b[32m119\u001b[39m     similarity_matrix = \u001b[43mknn_sparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_i\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mknn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    120\u001b[39m     all_matrices.append(similarity_matrix)\n\u001b[32m    122\u001b[39m fused_matrix = snf_sparse(all_matrices, K=\u001b[38;5;28mself\u001b[39m.knn, t=\u001b[38;5;28mself\u001b[39m.n_similarities, alpha=\u001b[38;5;28mself\u001b[39m.alpha)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/cohirf/cohirf/models/scsrgf.py:74\u001b[39m, in \u001b[36mknn_sparse\u001b[39m\u001b[34m(data, K)\u001b[39m\n\u001b[32m     72\u001b[39m nearest_neighbors.fit(data)\n\u001b[32m     73\u001b[39m graph = nearest_neighbors.kneighbors_graph(data, mode=\u001b[33m'\u001b[39m\u001b[33mdistance\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m sigma = \u001b[43mpairwise_distances\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m.mean()\n\u001b[32m     75\u001b[39m graph.data = np.exp(-graph.data / (\u001b[32m2\u001b[39m * sigma))\n\u001b[32m     76\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m graph\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/cohirf/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:218\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    214\u001b[39m         skip_parameter_validation=(\n\u001b[32m    215\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    216\u001b[39m         )\n\u001b[32m    217\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    224\u001b[39m     msg = re.sub(\n\u001b[32m    225\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    226\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    227\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    228\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/cohirf/lib/python3.11/site-packages/sklearn/metrics/pairwise.py:2477\u001b[39m, in \u001b[36mpairwise_distances\u001b[39m\u001b[34m(X, Y, metric, n_jobs, force_all_finite, ensure_all_finite, **kwds)\u001b[39m\n\u001b[32m   2474\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m distance.squareform(distance.pdist(X, metric=metric, **kwds))\n\u001b[32m   2475\u001b[39m     func = partial(distance.cdist, metric=metric, **kwds)\n\u001b[32m-> \u001b[39m\u001b[32m2477\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_parallel_pairwise\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/cohirf/lib/python3.11/site-packages/sklearn/metrics/pairwise.py:1960\u001b[39m, in \u001b[36m_parallel_pairwise\u001b[39m\u001b[34m(X, Y, func, n_jobs, **kwds)\u001b[39m\n\u001b[32m   1957\u001b[39m X, Y, dtype = _return_float_dtype(X, Y)\n\u001b[32m   1959\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m effective_n_jobs(n_jobs) == \u001b[32m1\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1960\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1962\u001b[39m \u001b[38;5;66;03m# enforce a threading backend to prevent data communication overhead\u001b[39;00m\n\u001b[32m   1963\u001b[39m fd = delayed(_dist_wrapper)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/cohirf/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:191\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    189\u001b[39m global_skip_validation = get_config()[\u001b[33m\"\u001b[39m\u001b[33mskip_parameter_validation\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    190\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[32m--> \u001b[39m\u001b[32m191\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    193\u001b[39m func_sig = signature(func)\n\u001b[32m    195\u001b[39m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/cohirf/lib/python3.11/site-packages/sklearn/metrics/pairwise.py:388\u001b[39m, in \u001b[36meuclidean_distances\u001b[39m\u001b[34m(X, Y, Y_norm_squared, squared, X_norm_squared)\u001b[39m\n\u001b[32m    382\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m Y_norm_squared.shape != (\u001b[32m1\u001b[39m, Y.shape[\u001b[32m0\u001b[39m]):\n\u001b[32m    383\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    384\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIncompatible dimensions for Y of shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mY.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m and \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    385\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mY_norm_squared of shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moriginal_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    386\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m388\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_euclidean_distances\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_norm_squared\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_norm_squared\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msquared\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/cohirf/lib/python3.11/site-packages/sklearn/metrics/pairwise.py:424\u001b[39m, in \u001b[36m_euclidean_distances\u001b[39m\u001b[34m(X, Y, X_norm_squared, Y_norm_squared, squared)\u001b[39m\n\u001b[32m    421\u001b[39m     distances = _euclidean_distances_upcast(X, XX, Y, YY)\n\u001b[32m    422\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    423\u001b[39m     \u001b[38;5;66;03m# if dtype is already float64, no need to chunk and upcast\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m424\u001b[39m     distances = -\u001b[32m2\u001b[39m * \u001b[43msafe_sparse_dot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m.\u001b[49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdense_output\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    425\u001b[39m     distances += XX\n\u001b[32m    426\u001b[39m     distances += YY\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/cohirf/lib/python3.11/site-packages/sklearn/utils/extmath.py:203\u001b[39m, in \u001b[36msafe_sparse_dot\u001b[39m\u001b[34m(a, b, dense_output)\u001b[39m\n\u001b[32m    201\u001b[39m         ret = xp.tensordot(a, b, axes=[-\u001b[32m1\u001b[39m, b_axis])\n\u001b[32m    202\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m203\u001b[39m     ret = \u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[43m@\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\n\u001b[32m    205\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    206\u001b[39m     sparse.issparse(a)\n\u001b[32m    207\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m sparse.issparse(b)\n\u001b[32m    208\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m dense_output\n\u001b[32m    209\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(ret, \u001b[33m\"\u001b[39m\u001b[33mtoarray\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    210\u001b[39m ):\n\u001b[32m    211\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.toarray()\n",
      "\u001b[31mMemoryError\u001b[39m: Unable to allocate 36.5 GiB for an array with shape (70000, 70000) and data type float64"
     ]
    }
   ],
   "source": [
    "seeds = [i for i in range(1)]\n",
    "aris = []\n",
    "times = []\n",
    "memories = []\n",
    "for seed in seeds:\n",
    "    experiment = OpenmlClusteringExperiment(\n",
    "        # model\n",
    "        experiment_name=\"test\",\n",
    "        model=\"SpectralSubspaceRandomization\",\n",
    "        seed_model=0,\n",
    "        # dataset\n",
    "        dataset_id=554,\n",
    "        standardize=True,\n",
    "        raise_on_error=True,\n",
    "        **experiment_params,\n",
    "    )\n",
    "    result = experiment.run(return_results=True)[0]\n",
    "    ari = result[\"evaluate_model_return\"][\"adjusted_rand\"]\n",
    "    time = result[\"fit_model_return\"][\"elapsed_time\"]\n",
    "    max_memory = result[\"max_memory_used_after_fit\"]\n",
    "    aris.append(ari)\n",
    "    times.append(time)\n",
    "    memories.append(max_memory)\n",
    "clear_output(wait=True)\n",
    "df = pd.DataFrame({\"ARI\": aris, \"Time\": times, \"Memory\": memories})\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c407ffdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds = [i for i in range(1)]\n",
    "aris = []\n",
    "times = []\n",
    "memories = []\n",
    "for seed in seeds:\n",
    "    experiment = OpenmlClusteringExperiment(\n",
    "        # model\n",
    "        experiment_name=\"test\",\n",
    "        model=\"SpectralSubspaceRandomization\",\n",
    "        seed_model=0,\n",
    "        # dataset\n",
    "        dataset_id=554,\n",
    "        standardize=True,\n",
    "        raise_on_error=True,\n",
    "        **experiment_params,\n",
    "    )\n",
    "    result = experiment.run(return_results=True)[0]\n",
    "    ari = result[\"evaluate_model_return\"][\"adjusted_rand\"]\n",
    "    time = result[\"fit_model_return\"][\"elapsed_time\"]\n",
    "    max_memory = result[\"max_memory_used_after_fit\"]\n",
    "    aris.append(ari)\n",
    "    times.append(time)\n",
    "    memories.append(max_memory)\n",
    "clear_output(wait=True)\n",
    "df = pd.DataFrame({\"ARI\": aris, \"Time\": times, \"Memory\": memories})\n",
    "print(df.describe())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cohirf",
   "language": "python",
   "name": "cohirf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
